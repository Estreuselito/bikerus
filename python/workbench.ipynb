{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "Python 3.8.6 64-bit",
   "display_name": "Python 3.8.6 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "4cd7ab41f5fca4b9b44701077e38c5ffd31fe66a6cab21e0214b68d958d0e462"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_preprocessing import decompress_pickle, compressed_pickle\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# load data\n",
    "df = decompress_pickle(\"../data/preprocessed/BikeRental_complete.pbz2\")"
   ]
  },
  {
   "source": [
    "from pandas_profiling import ProfileReport\n",
    "profile = ProfileReport(df, title='Bike Share Rental Pandas Profiling Report', explorative = True, dark_mode = True)\n",
    "profile.to_file(output_file='Bike Share Rental Pandas Profiling Report.html')"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "             datetime      dteday  season   yr  mnth  hr  holiday  weekday  \\\n",
       "0 2011-01-01 00:00:00  2011-01-01     1.0  0.0     1   0      0.0        5   \n",
       "1 2011-01-01 01:00:00  2011-01-01     1.0  0.0     1   1      0.0        5   \n",
       "2 2011-01-01 02:00:00  2011-01-01     1.0  0.0     1   2      0.0        5   \n",
       "3 2011-01-01 03:00:00  2011-01-01     1.0  0.0     1   3      0.0        5   \n",
       "4 2011-01-01 04:00:00  2011-01-01     1.0  0.0     1   4      0.0        5   \n",
       "\n",
       "   workingday  weathersit  temp   atemp   hum  windspeed  casual  registered  \\\n",
       "0         0.0         1.0  0.24  0.2879  0.81        0.0     3.0        13.0   \n",
       "1         0.0         1.0  0.22  0.2727  0.80        0.0     8.0        32.0   \n",
       "2         0.0         1.0  0.22  0.2727  0.80        0.0     5.0        27.0   \n",
       "3         0.0         1.0  0.24  0.2879  0.75        0.0     3.0        10.0   \n",
       "4         0.0         1.0  0.24  0.2879  0.75        0.0     0.0         1.0   \n",
       "\n",
       "    cnt  \n",
       "0  16.0  \n",
       "1  40.0  \n",
       "2  32.0  \n",
       "3  13.0  \n",
       "4   1.0  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>datetime</th>\n      <th>dteday</th>\n      <th>season</th>\n      <th>yr</th>\n      <th>mnth</th>\n      <th>hr</th>\n      <th>holiday</th>\n      <th>weekday</th>\n      <th>workingday</th>\n      <th>weathersit</th>\n      <th>temp</th>\n      <th>atemp</th>\n      <th>hum</th>\n      <th>windspeed</th>\n      <th>casual</th>\n      <th>registered</th>\n      <th>cnt</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2011-01-01 00:00:00</td>\n      <td>2011-01-01</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>5</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.24</td>\n      <td>0.2879</td>\n      <td>0.81</td>\n      <td>0.0</td>\n      <td>3.0</td>\n      <td>13.0</td>\n      <td>16.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2011-01-01 01:00:00</td>\n      <td>2011-01-01</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0.0</td>\n      <td>5</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.22</td>\n      <td>0.2727</td>\n      <td>0.80</td>\n      <td>0.0</td>\n      <td>8.0</td>\n      <td>32.0</td>\n      <td>40.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2011-01-01 02:00:00</td>\n      <td>2011-01-01</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1</td>\n      <td>2</td>\n      <td>0.0</td>\n      <td>5</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.22</td>\n      <td>0.2727</td>\n      <td>0.80</td>\n      <td>0.0</td>\n      <td>5.0</td>\n      <td>27.0</td>\n      <td>32.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2011-01-01 03:00:00</td>\n      <td>2011-01-01</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1</td>\n      <td>3</td>\n      <td>0.0</td>\n      <td>5</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.24</td>\n      <td>0.2879</td>\n      <td>0.75</td>\n      <td>0.0</td>\n      <td>3.0</td>\n      <td>10.0</td>\n      <td>13.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2011-01-01 04:00:00</td>\n      <td>2011-01-01</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1</td>\n      <td>4</td>\n      <td>0.0</td>\n      <td>5</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.24</td>\n      <td>0.2879</td>\n      <td>0.75</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('cnt', axis = 1)\n",
    "X = X.drop('datetime', axis = 1)\n",
    "X = X.drop('dteday', axis = 1)\n",
    "X = X.drop('registered', axis = 1)\n",
    "X = X.drop('casual', axis=1)\n",
    "#X = X.drop('yr', axis=1)\n",
    "Y = df['cnt']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(14035,)\n(3509,)\nY_train_mean = 187.66539347058855\nY_train_meandev = 459541132.40605336\nY_test_meandev = 116954039.11552408\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.2, random_state=0)\n",
    "print(Y_train.shape)\n",
    "print(Y_test.shape)\n",
    "\n",
    "Y_train_mean = Y_train.mean()\n",
    "print(\"Y_train_mean =\", Y_train_mean)\n",
    "Y_train_meandev = sum((Y_train-Y_train_mean)**2)\n",
    "print(\"Y_train_meandev =\", Y_train_meandev)\n",
    "Y_test_meandev = sum((Y_test-Y_train_mean)**2)\n",
    "print(\"Y_test_meandev =\", Y_test_meandev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Y_train_mean = 177.86125170998633\nY_train_meandev = 429659156.4202601\nY_test_meandev = 148598422.69268876\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "tss = TimeSeriesSplit()\n",
    "\n",
    "for train_index, test_index in tss.split(X):\n",
    "    X_train, X_test = X.iloc[train_index, :], X.iloc[test_index,:]\n",
    "    Y_train, Y_test = Y.iloc[train_index], Y.iloc[test_index]\n",
    "\n",
    "Y_train_mean = Y_train.mean()\n",
    "print(\"Y_train_mean =\", Y_train_mean)\n",
    "Y_train_meandev = sum((Y_train-Y_train_mean)**2)\n",
    "print(\"Y_train_meandev =\", Y_train_meandev)\n",
    "Y_test_meandev = sum((Y_test-Y_train_mean)**2)\n",
    "print(\"Y_test_meandev =\", Y_test_meandev)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create report dataframe\n",
    "report = pd.DataFrame(columns=['Model','R2.Train','R2.Test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "R2 = 0.4014026119945089\nPseudo-R2 = 0.3564842588430778\n"
     ]
    }
   ],
   "source": [
    "################\n",
    "#     OLS      #\n",
    "################\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "lm = LinearRegression()\n",
    "lm.fit(X_train, Y_train)\n",
    "Y_train_pred = lm.predict(X_train)\n",
    "Y_train_dev = sum((Y_train-Y_train_pred)**2)\n",
    "r2 = 1 - Y_train_dev/Y_train_meandev\n",
    "print(\"R2 =\", r2)\n",
    "Y_test_pred = lm.predict(X_test)\n",
    "Y_test_dev = sum((Y_test-Y_test_pred)**2)\n",
    "pseudor2 = 1 - Y_test_dev/Y_test_meandev\n",
    "print(\"Pseudo-R2 =\", pseudor2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{'fit_intercept': False}\nR2 = 0.40138392312863835\nPseudo-R2 = 0.35610452597060305\n"
     ]
    }
   ],
   "source": [
    "# OLS with Cross Validation and Grid Search\n",
    "from sklearn.linear_model import LinearRegression\n",
    "lmCV = LinearRegression()\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "param_grid = { \n",
    "    'fit_intercept':[True,False]\n",
    "}\n",
    "CV_olsmodel = GridSearchCV(estimator=lmCV, param_grid=param_grid, cv=10)\n",
    "CV_olsmodel.fit(X_train, Y_train)\n",
    "print(CV_olsmodel.best_params_)\n",
    "lmCV = lmCV.set_params(**CV_olsmodel.best_params_)\n",
    "lmCV.fit(X_train, Y_train)\n",
    "Y_train_pred = lmCV.predict(X_train)\n",
    "Y_train_dev = sum((Y_train-Y_train_pred)**2)\n",
    "r2 = 1 - Y_train_dev/Y_train_meandev\n",
    "print(\"R2 =\", r2)\n",
    "Y_test_pred = lmCV.predict(X_test)\n",
    "Y_test_dev = sum((Y_test-Y_test_pred)**2)\n",
    "pseudor2 = 1 - Y_test_dev/Y_test_meandev\n",
    "print(\"Pseudo-R2 =\", pseudor2)\n",
    "report.loc[len(report)] = ['OLS RegressionCV', r2, pseudor2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "R2 = 0.4014007828305891\nPseudo-R2 = 0.35644490880869306\n"
     ]
    }
   ],
   "source": [
    "####################\n",
    "# Ridge Regression #\n",
    "####################\n",
    "\n",
    "from sklearn.linear_model import Ridge\n",
    "ridgereg = Ridge(alpha=2)\n",
    "ridgereg.fit(X_train, Y_train)\n",
    "Y_train_pred = ridgereg.predict(X_train)\n",
    "Y_train_dev = sum((Y_train-Y_train_pred)**2)\n",
    "r2 = 1 - Y_train_dev/Y_train_meandev\n",
    "print(\"R2 =\", r2)\n",
    "Y_test_pred = ridgereg.predict(X_test)\n",
    "Y_test_dev = sum((Y_test-Y_test_pred)**2)\n",
    "pseudor2 = 1 - Y_test_dev/Y_test_meandev\n",
    "print(\"Pseudo-R2 =\", pseudor2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{'alpha': 25}\nR2 = 0.401232188280927\nPseudo-R2 = 0.35494181456372287\n"
     ]
    }
   ],
   "source": [
    "# find best lambda (alphas)\n",
    "from sklearn.linear_model import Ridge\n",
    "ridgeregCV = Ridge()\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "param_grid = { \n",
    "    'alpha': [25,10,4,2,1.0,0.8,0.5,0.3,0.2,0.1,0.05,0.02,0.01]\n",
    "}\n",
    "CV_rrmodel = GridSearchCV(estimator=ridgeregCV, param_grid=param_grid, cv=10)\n",
    "CV_rrmodel.fit(X_train, Y_train)\n",
    "print(CV_rrmodel.best_params_)\n",
    "ridgeregCV = ridgeregCV.set_params(**CV_rrmodel.best_params_)\n",
    "ridgeregCV.fit(X_train, Y_train)\n",
    "Y_train_pred = ridgeregCV.predict(X_train)\n",
    "Y_train_dev = sum((Y_train-Y_train_pred)**2)\n",
    "r2 = 1 - Y_train_dev/Y_train_meandev\n",
    "print(\"R2 =\", r2)\n",
    "Y_test_pred = ridgeregCV.predict(X_test)\n",
    "Y_test_dev = sum((Y_test-Y_test_pred)**2)\n",
    "pseudor2 = 1 - Y_test_dev/Y_test_meandev\n",
    "print(\"Pseudo-R2 =\", pseudor2)\n",
    "report.loc[len(report)] = ['Ridge RegressionCV', r2, pseudor2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "R2 = 0.34406280877315265\n",
      "Pseudo-R2 = 0.25487956438543224\n"
     ]
    }
   ],
   "source": [
    "#############################\n",
    "# Support Vector Regression #\n",
    "#############################\n",
    "\n",
    "# linear kernel\n",
    "from sklearn.svm import SVR\n",
    "LinSVRreg = SVR(kernel='linear', C=1.0, epsilon=0.1)\n",
    "LinSVRreg.fit(X_train, Y_train)\n",
    "Y_train_pred = LinSVRreg.predict(X_train)\n",
    "Y_train_dev = sum((Y_train-Y_train_pred)**2)\n",
    "r2 = 1 - Y_train_dev/Y_train_meandev\n",
    "print(\"R2 =\", r2)\n",
    "Y_test_pred = LinSVRreg.predict(X_test)\n",
    "Y_test_dev = sum((Y_test-Y_test_pred)**2)\n",
    "pseudor2 = 1 - Y_test_dev/Y_test_meandev\n",
    "print(\"Pseudo-R2 =\", pseudor2)\n",
    "report.loc[len(report)] = ['Support Vector RegressionCV', r2, pseudor2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "R2 = 0.38574885793733726\n",
      "Pseudo-R2 = 0.28329777895635433\n"
     ]
    }
   ],
   "source": [
    "# radial kernel\n",
    "RbfSVRreg = SVR(kernel='rbf', C=1.0, epsilon=0.1)\n",
    "RbfSVRreg.fit(X_train, Y_train)\n",
    "Y_train_pred = RbfSVRreg.predict(X_train)\n",
    "Y_train_dev = sum((Y_train-Y_train_pred)**2)\n",
    "r2 = 1 - Y_train_dev/Y_train_meandev\n",
    "print(\"R2 =\", r2)\n",
    "Y_test_pred = RbfSVRreg.predict(X_test)\n",
    "Y_test_dev = sum((Y_test-Y_test_pred)**2)\n",
    "pseudor2 = 1 - Y_test_dev/Y_test_meandev\n",
    "print(\"Pseudo-R2 =\", pseudor2)\n",
    "report.loc[len(report)] = ['Support Vector RegressionCV', r2, pseudor2]"
   ]
  },
  {
   "source": [
    "from sklearn.svm import SVR\n",
    "RbfSVRregCV = SVR()\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "param_grid = { \n",
    "    'kernel': [\"linear\", \"rbf\"], \n",
    "    'C': [1, 3, 5, 8, 10],\n",
    "    'epsilon': [0.0, 0.025, 0.05, 0.075, 0.1],\n",
    "    'gamma' : [0., 1., 2., 3., 4.]\n",
    "}\n",
    "CV_svrmodel = GridSearchCV(estimator=RbfSVRregCV, param_grid=param_grid, cv=10)\n",
    "CV_svrmodel.fit(X_train, Y_train)\n",
    "print(CV_svrmodel.best_params_)\n",
    "RbfSVRregCV = RbfSVRregCV.set_params(**CV_svrmodel.best_params_)\n",
    "RbfSVRregCV.fit(X_train, Y_train)\n",
    "Y_train_pred = RbfSVRregCV.predict(X_train)\n",
    "Y_train_dev = sum((Y_train-Y_train_pred)**2)\n",
    "r2 = 1 - Y_train_dev/Y_train_meandev\n",
    "print(\"R2 =\", r2)\n",
    "Y_test_pred = RbfSVRregCV.predict(X_test)\n",
    "Y_test_dev = sum((Y_test-Y_test_pred)**2)\n",
    "pseudor2 = 1 - Y_test_dev/Y_test_meandev\n",
    "print(\"Pseudo-R2 =\", pseudor2)\n",
    "report.loc[len(report)] = ['Support Vector RegressionCV', r2, pseudor2]"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "R2 = 0.5882970964463183\nPseudo-R2 = 0.5589824018612105\n"
     ]
    }
   ],
   "source": [
    "##################\n",
    "# Neural Network #\n",
    "##################\n",
    "\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "NNetRreg = MLPRegressor(solver='lbfgs', max_iter=10000, hidden_layer_sizes=(10,), random_state=0)\n",
    "NNetRreg.fit(X_train, Y_train)\n",
    "Y_train_pred = NNetRreg.predict(X_train)\n",
    "Y_train_dev = sum((Y_train-Y_train_pred)**2)\n",
    "r2 = 1 - Y_train_dev/Y_train_meandev\n",
    "print(\"R2 =\", r2)\n",
    "Y_test_pred = NNetRreg.predict(X_test)\n",
    "Y_test_dev = sum((Y_test-Y_test_pred)**2)\n",
    "pseudor2 = 1 - Y_test_dev/Y_test_meandev\n",
    "print(\"Pseudo-R2 =\", pseudor2)\n",
    "report.loc[len(report)] = ['Neural NetworkCV', r2, pseudor2]"
   ]
  },
  {
   "source": [
    "from sklearn.neural_network import MLPRegressor\n",
    "NNetRregCV = MLPRegressor(solver='lbfgs', max_iter=10000, random_state=0)\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "param_grid = { \n",
    "    'learning_rate': [\"constant\", \"invscaling\", \"adaptive\"],\n",
    "    'hidden_layer_sizes': [(5,), (8,), (10,), (13,)],\n",
    "    'alpha': [0.0, 0.0025, 0.005, 0.0075, 0.01, 0.1],\n",
    "    'activation': [\"logistic\", \"relu\", \"tanh\"]\n",
    "}\n",
    "CV_nnmodel = GridSearchCV(estimator=NNetRregCV, param_grid=param_grid, cv=10)\n",
    "CV_nnmodel.fit(X_train, Y_train)\n",
    "print(CV_nnmodel.best_params_)\n",
    "NNetRregCV = NNetRregCV.set_params(**CV_nnmodel.best_params_)\n",
    "NNetRregCV.fit(X_train, Y_train)\n",
    "Y_train_pred = NNetRregCV.predict(X_train)\n",
    "Y_train_dev = sum((Y_train-Y_train_pred)**2)\n",
    "r2 = 1 - Y_train_dev/Y_train_meandev\n",
    "print(\"R2 =\", r2)\n",
    "Y_test_pred = NNetRregCV.predict(X_test)\n",
    "Y_test_dev = sum((Y_test-Y_test_pred)**2)\n",
    "pseudor2 = 1 - Y_test_dev/Y_test_meandev\n",
    "print(\"Pseudo-R2 =\", pseudor2)\n",
    "report.loc[len(report)] = ['Neural NetworkCV', r2, pseudor2]"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "R2 = 0.9931131619571687\nPseudo-R2 = 0.8898634544501338\n"
     ]
    }
   ],
   "source": [
    "#################\n",
    "# Random Forest #\n",
    "#################\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "RForreg = RandomForestRegressor(n_estimators=500, random_state=0)\n",
    "RForreg.fit(X_train, Y_train)\n",
    "Y_train_pred = RForreg.predict(X_train)\n",
    "Y_train_dev = sum((Y_train-Y_train_pred)**2)\n",
    "r2 = 1 - Y_train_dev/Y_train_meandev\n",
    "print(\"R2 =\", r2)\n",
    "Y_test_pred = RForreg.predict(X_test)\n",
    "Y_test_dev = sum((Y_test-Y_test_pred)**2)\n",
    "pseudor2 = 1 - Y_test_dev/Y_test_meandev\n",
    "print(\"Pseudo-R2 =\", pseudor2)\n",
    "report.loc[len(report)] = ['Random ForestCV', r2, pseudor2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "RForregCV = RandomForestRegressor(random_state=0)\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "param_grid = { \n",
    "    'max_depth': [ 4.,  5.,  6.,  7.,  8.],\n",
    "    'n_estimators': [ 10,  50,  100, 150, 200]\n",
    "}\n",
    "CV_rfmodel = GridSearchCV(estimator=RForregCV, param_grid=param_grid, cv=10)\n",
    "CV_rfmodel.fit(X_train, Y_train)\n",
    "print(CV_rfmodel.best_params_)\n",
    "RForregCV = RForregCV.set_params(**CV_rfmodel.best_params_)\n",
    "RForregCV.fit(X_train, Y_train)\n",
    "Y_train_pred = RForregCV.predict(X_train)\n",
    "Y_train_dev = sum((Y_train-Y_train_pred)**2)\n",
    "r2 = 1 - Y_train_dev/Y_train_meandev\n",
    "print(\"R2 =\", r2)\n",
    "Y_test_pred = RForregCV.predict(X_test)\n",
    "Y_test_dev = sum((Y_test-Y_test_pred)**2)\n",
    "pseudor2 = 1 - Y_test_dev/Y_test_meandev\n",
    "print(\"Pseudo-R2 =\", pseudor2)\n",
    "report.loc[len(report)] = ['Random ForestCV', r2, pseudor2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "R2 = 0.8821010671844156\nPseudo-R2 = 0.7904120645466031\n"
     ]
    }
   ],
   "source": [
    "#####################\n",
    "# Gradient Boosting #\n",
    "#####################\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "GBoostreg = GradientBoostingRegressor(random_state=0)\n",
    "GBoostreg.fit(X_train, Y_train)\n",
    "Y_train_pred = GBoostreg.predict(X_train)\n",
    "Y_train_dev = sum((Y_train-Y_train_pred)**2)\n",
    "r2 = 1 - Y_train_dev/Y_train_meandev\n",
    "print(\"R2 =\", r2)\n",
    "Y_test_pred = GBoostreg.predict(X_test)\n",
    "Y_test_dev = sum((Y_test-Y_test_pred)**2)\n",
    "pseudor2 = 1 - Y_test_dev/Y_test_meandev\n",
    "print(\"Pseudo-R2 =\", pseudor2)\n",
    "report.loc[len(report)] = ['Gradient BoostingCV', r2, pseudor2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "GBoostregCV = GradientBoostingRegressor(random_state=0)\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "param_grid = { \n",
    "    'max_depth': [ 3., 4., 5.],\n",
    "    'subsample': [0.7, 0.8, 0.9],\n",
    "    'n_estimators': [50, 100,150],\n",
    "    'learning_rate': [0.1, 0.2, 0.3]\n",
    "}\n",
    "CV_gbmodel = GridSearchCV(estimator=GBoostregCV, param_grid=param_grid, cv=10)\n",
    "CV_gbmodel.fit(X_train, Y_train)\n",
    "print(CV_gbmodel.best_params_)\n",
    "GBoostregCV = GBoostregCV.set_params(**CV_gbmodel.best_params_)\n",
    "GBoostregCV.fit(X_train, Y_train)\n",
    "Y_train_pred = GBoostregCV.predict(X_train)\n",
    "Y_train_dev = sum((Y_train-Y_train_pred)**2)\n",
    "r2 = 1 - Y_train_dev/Y_train_meandev\n",
    "print(\"R2 =\", r2)\n",
    "Y_test_pred = GBoostregCV.predict(X_test)\n",
    "Y_test_dev = sum((Y_test-Y_test_pred)**2)\n",
    "pseudor2 = 1 - Y_test_dev/Y_test_meandev\n",
    "print(\"Pseudo-R2 =\", pseudor2)\n",
    "report.loc[len(report)] = ['Gradient BoostingCV', r2, pseudor2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "                         Model  R2.Train   R2.Test\n0             OLS RegressionCV  0.401384  0.356105\n1           Ridge RegressionCV  0.401232  0.354942\n2  Support Vector RegressionCV  0.344063  0.254880\n3  Support Vector RegressionCV  0.385749  0.283298\n4             Neural NetworkCV  0.588297  0.558982\n5              Random ForestCV  0.993113  0.889863\n6          Gradient BoostingCV  0.882101  0.790412\n"
     ]
    }
   ],
   "source": [
    "################\n",
    "# Final Report #\n",
    "################\n",
    "\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}